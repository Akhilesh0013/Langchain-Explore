{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b01850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.tools import ArxivQueryRun , WikipediaQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper , WikipediaAPIWrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "from langgraph.graph import StateGraph , START , END\n",
    "from langgraph.prebuilt import ToolNode , tools_condition\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages , Annotated \n",
    "from langchain.messages import HumanMessage , AIMessage , AnyMessage\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46113e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "802e052d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/tpzdhn2d0rv1nscqt75gbvgw0000gn/T/ipykernel_35919/3784891661.py:7: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
      "  tavily = TavilySearchResults()\n"
     ]
    }
   ],
   "source": [
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results= 2 , doc_content_chars_max= 500) \n",
    "arxiv = ArxivQueryRun(api_wrapper= arxiv_wrapper)\n",
    "\n",
    "wiki_wrapper = WikipediaAPIWrapper(top_k_results= 1 , doc_content_chars_max=500)\n",
    "wiki = WikipediaQueryRun(api_wrapper= wiki_wrapper)\n",
    "\n",
    "tavily = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fd404aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom functions\n",
    "\n",
    "def add(a : int , b: int) -> int :\n",
    "\n",
    "    \"\"\" Function Returns sum of two numbers\n",
    "\n",
    "    Args:\n",
    "        a (int): Integer \n",
    "        b (int): Integer \n",
    "\n",
    "    Returns:\n",
    "        int: Integer a+b\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return a+b \n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Function returns the product of two numbers.\n",
    "\n",
    "    Args:\n",
    "        a (int): Integer A\n",
    "        b (int): Integer B\n",
    "\n",
    "    Returns:\n",
    "        int: Integer A * B\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Function returns the division of two numbers.\n",
    "\n",
    "    Args:\n",
    "        a (int): Integer A\n",
    "        b (int): Integer B\n",
    "\n",
    "    Returns:\n",
    "        float: Result of A / B\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If b is zero.\n",
    "    \"\"\"\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Division by zero is not allowed.\")\n",
    "    return a / b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79749219",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [arxiv , wiki , tavily , add, multiply, divide]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50517fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict) :\n",
    "    messages : Annotated[list[AnyMessage],add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3edcf8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c057dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model= \"openai/gpt-oss-20b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cee697e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "597b13c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node Definition\n",
    "\n",
    "def chatbot(state : State) :\n",
    "\n",
    "    return {\"messages\" : [llm_with_tools.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebd55bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nodes\n",
    "graph.add_node(\"chatbot\" , chatbot)\n",
    "graph.add_node(\"tools\" , ToolNode(tools))\n",
    "\n",
    "graph.add_edge(START , \"chatbot\")\n",
    "graph.add_conditional_edges(\"chatbot\" , tools_condition)\n",
    "\n",
    "graph.add_edge(\"tools\" , \"chatbot\")\n",
    "\n",
    "\n",
    "graph_builder = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa1f7239",
   "metadata": {},
   "outputs": [],
   "source": [
    "response= graph_builder.invoke({\"messages\" : [\"What is 2025 + 2025 , Recent AI news\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb88d78",
   "metadata": {},
   "source": [
    "# Agent with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a2b6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55f0a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "996bb5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a9acf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17ff6dff0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add nodes\n",
    "graph.add_node(\"chatbot\" , chatbot)\n",
    "graph.add_node(\"tools\" , ToolNode(tools))\n",
    "\n",
    "graph.add_edge(START , \"chatbot\")\n",
    "graph.add_conditional_edges(\"chatbot\" , tools_condition)\n",
    "\n",
    "graph.add_edge(\"tools\" , \"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "140afc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_memory = graph.compile(checkpointer= memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12077695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify thread \n",
    "\n",
    "config = {\"configurable\" : {\"thread_id\" : 1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96c53e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is 25 + 25', additional_kwargs={}, response_metadata={}, id='66acb729-6628-4a9e-aa7f-e5a174777b0c'),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to answer simple math. The user asked \"What is 25 + 25\". We can compute 50. We can also use the add function. Let\\'s use the add function.', 'tool_calls': [{'id': 'fc_9c4394fa-8faf-4459-a7b2-90a989312ce9', 'function': {'arguments': '{\"a\":25,\"b\":25}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 385, 'total_tokens': 451, 'completion_time': 0.06532435, 'prompt_time': 0.020294459, 'queue_time': 0.008106955, 'total_time': 0.085618809, 'completion_tokens_details': {'reasoning_tokens': 40}}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_3417a662f8', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--6a77518e-065c-41cf-9886-0d2af3a76e19-0', tool_calls=[{'name': 'add', 'args': {'a': 25, 'b': 25}, 'id': 'fc_9c4394fa-8faf-4459-a7b2-90a989312ce9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 385, 'output_tokens': 66, 'total_tokens': 451, 'output_token_details': {'reasoning': 40}}),\n",
       "  ToolMessage(content='50', name='add', id='0bc6a631-d97e-44e1-8fc3-358ffe6f9dd9', tool_call_id='fc_9c4394fa-8faf-4459-a7b2-90a989312ce9'),\n",
       "  AIMessage(content='50', additional_kwargs={'reasoning_content': 'User asked \"What is 25 + 25\". We already used add function. Response should be 50.'}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 416, 'total_tokens': 450, 'completion_time': 0.03727153, 'prompt_time': 0.021827155, 'queue_time': 0.008078028, 'total_time': 0.059098685, 'completion_tokens_details': {'reasoning_tokens': 24}}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_017d3da75a', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--5e9103dc-2238-4c94-aae2-bc6a907d41e3-0', usage_metadata={'input_tokens': 416, 'output_tokens': 34, 'total_tokens': 450, 'output_token_details': {'reasoning': 24}})]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_memory.invoke({\"messages\" : [\"What is 25 + 25\"]}, config= config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c84335e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is 25 + 25', additional_kwargs={}, response_metadata={}, id='66acb729-6628-4a9e-aa7f-e5a174777b0c'),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to answer simple math. The user asked \"What is 25 + 25\". We can compute 50. We can also use the add function. Let\\'s use the add function.', 'tool_calls': [{'id': 'fc_9c4394fa-8faf-4459-a7b2-90a989312ce9', 'function': {'arguments': '{\"a\":25,\"b\":25}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 385, 'total_tokens': 451, 'completion_time': 0.06532435, 'prompt_time': 0.020294459, 'queue_time': 0.008106955, 'total_time': 0.085618809, 'completion_tokens_details': {'reasoning_tokens': 40}}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_3417a662f8', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--6a77518e-065c-41cf-9886-0d2af3a76e19-0', tool_calls=[{'name': 'add', 'args': {'a': 25, 'b': 25}, 'id': 'fc_9c4394fa-8faf-4459-a7b2-90a989312ce9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 385, 'output_tokens': 66, 'total_tokens': 451, 'output_token_details': {'reasoning': 40}}),\n",
       "  ToolMessage(content='50', name='add', id='0bc6a631-d97e-44e1-8fc3-358ffe6f9dd9', tool_call_id='fc_9c4394fa-8faf-4459-a7b2-90a989312ce9'),\n",
       "  AIMessage(content='50', additional_kwargs={'reasoning_content': 'User asked \"What is 25 + 25\". We already used add function. Response should be 50.'}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 416, 'total_tokens': 450, 'completion_time': 0.03727153, 'prompt_time': 0.021827155, 'queue_time': 0.008078028, 'total_time': 0.059098685, 'completion_tokens_details': {'reasoning_tokens': 24}}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_017d3da75a', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--5e9103dc-2238-4c94-aae2-bc6a907d41e3-0', usage_metadata={'input_tokens': 416, 'output_tokens': 34, 'total_tokens': 450, 'output_token_details': {'reasoning': 24}}),\n",
       "  HumanMessage(content='What is that plus 25', additional_kwargs={}, response_metadata={}, id='4711edd1-bae6-4ce1-ad97-a0aa7eaff773'),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to add 25 to previous result 50. So 50 + 25 = 75. Use add function.', 'tool_calls': [{'id': 'fc_65708157-1043-49f2-959d-feed0807d7bd', 'function': {'arguments': '{\"a\":50,\"b\":25}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 433, 'total_tokens': 486, 'completion_time': 0.053344276, 'prompt_time': 0.473823734, 'queue_time': 0.008041488, 'total_time': 0.52716801, 'completion_tokens_details': {'reasoning_tokens': 27}}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_d08f3e4cc0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--e6426086-c378-4f5d-aac7-2c04ecf850c9-0', tool_calls=[{'name': 'add', 'args': {'a': 50, 'b': 25}, 'id': 'fc_65708157-1043-49f2-959d-feed0807d7bd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 433, 'output_tokens': 53, 'total_tokens': 486, 'output_token_details': {'reasoning': 27}}),\n",
       "  ToolMessage(content='75', name='add', id='4590a21a-4f22-43bd-a698-e3f054198156', tool_call_id='fc_65708157-1043-49f2-959d-feed0807d7bd'),\n",
       "  AIMessage(content='75', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 464, 'total_tokens': 469, 'completion_time': 0.004941193, 'prompt_time': 0.015842925, 'queue_time': 0.007864101, 'total_time': 0.020784118, 'prompt_tokens_details': {'cached_tokens': 256}}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_3417a662f8', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--8a8d19d3-c349-49c9-a0dc-3ba6f4bf66cc-0', usage_metadata={'input_tokens': 464, 'output_tokens': 5, 'total_tokens': 469, 'input_token_details': {'cache_read': 256}})]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_memory.invoke({\"messages\" : [\"What is that plus 25\"]}, config= config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f9e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
