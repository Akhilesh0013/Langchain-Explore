{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca71d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain\n",
    "#pip install langchain-groq\n",
    "#pip install langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a11a6e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.messages import HumanMessage , SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a50cf4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48e5425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98b3acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34e0e3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model= \"llama-3.1-8b-instant\" , api_key= groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98dfa041",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "\n",
    "    SystemMessage(\"You are a helpful translator that STRICTLY translates English to French\") , \n",
    "    HumanMessage(\"Hello! How are you?\")\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ed9c65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bonjour ! Je vais bien, merci. Comment allez-vous ?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a7163a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b029218",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b53651d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bonjour ! Je vais bien, merci.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd251d1",
   "metadata": {},
   "source": [
    "# ChatPrompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68459884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4f98d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "\n",
    "    [\n",
    "    (\"system\" , \"You are a helpful assistant\"), \n",
    "    (\"human\" , \"{input}\")\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14655a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7cb8479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70801878",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is a Neutron Star\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d91fa475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A neutron star is a highly dense and extremely massive celestial body that is formed from the remnants of a massive star that has undergone a supernova explosion. It is essentially a star that is composed almost entirely of neutrons, with a small amount of protons and electrons.\\n\\nHere are some fascinating facts about neutron stars:\\n\\n1. **Density**: Neutron stars are incredibly dense objects, with a density that is typically 100 billion times greater than that of water. This means that a sugar-cube-sized amount of neutron star material would weigh about a billion tons!\\n2. **Mass**: Neutron stars are incredibly massive, with a mass that is typically between 1.4 and 2.1 times the mass of the sun. This is because the original star that collapsed to form the neutron star had a mass that was at least three to four times greater than the sun.\\n3. **Size**: Despite their massive size, neutron stars are incredibly small, with a diameter that is typically between 10 and 20 kilometers (6.2 and 12.4 miles).\\n4. **Surface gravity**: The surface gravity of a neutron star is so strong that it would stretch and compress any object that gets too close, causing it to experience intense tidal forces.\\n5. **Rotation**: Neutron stars are known to rotate extremely quickly, with some rotating hundreds of times per second. This rapid rotation gives rise to the phenomenon of pulsars, which emit beams of radiation that sweep through space like lighthouses.\\n6. **Magnetic field**: Neutron stars have incredibly strong magnetic fields, which can be trillions of times stronger than the Earth's magnetic field. This magnetic field can accelerate particles to high energies, creating powerful beams of radiation.\\n7. **Age**: Neutron stars are relatively young objects, with most forming from the remnants of supernovae that occurred in the past few thousand years.\\n\\nNeutron stars are incredibly fascinating objects that have captured the imagination of scientists and the general public alike. Their extreme properties make them ideal objects for study, and their discovery has helped us to better understand the behavior of matter at extreme densities.\\n\\nTypes of Neutron Stars:\\n\\n1. **Rotating Neutron Stars (Pulsars)**: These neutron stars rotate rapidly and emit beams of radiation that sweep through space, creating a lighthouse-like effect.\\n2. **Magnetars**: These neutron stars have incredibly strong magnetic fields that can accelerate particles to high energies, creating powerful beams of radiation.\\n3. **Soft Gamma Repeaters (SGRs)**: These neutron stars are capable of emitting intense bursts of gamma radiation, which are thought to be caused by the star's strong magnetic field.\\n4. **Supramassive Neutron Stars**: These neutron stars have masses that are greater than the maximum mass allowed for a neutron star, which is about 2.1 times the mass of the sun.\\n\\nNeutron stars are an area of ongoing research, and scientists continue to study these objects using a variety of techniques, including X-ray and gamma-ray astronomy, radio astronomy, and gravitational wave astronomy.\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({ \"input\" : prompt })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa35bd6",
   "metadata": {},
   "source": [
    "# Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc9d5241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "from langchain_core.messages import HumanMessage , AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f980f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62f3a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq( model= 'llama-3.1-8b-instant' , api_key = groq_api_key )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4452de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_session_history(session_id : str) -> BaseChatMessageHistory :\n",
    "\n",
    "    if session_id not in store :\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    \n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cddcb670",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = { \"configurable\" : {\"session_id\" : \"chat1\"} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd849469",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = RunnableWithMessageHistory(model , get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "942248b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to chat with you again, Akhilesh. It's good to see you're still working as a Data Scientist. How's your work going? Any exciting projects or accomplishments you'd like to share?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 294, 'total_tokens': 338, 'completion_time': 0.068971433, 'prompt_time': 0.016149531, 'queue_time': 0.054814094, 'total_time': 0.085120964}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9ca2574dca', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--69f8c4e4-0e15-4d35-9532-cbf42c5fd630-0', usage_metadata={'input_tokens': 294, 'output_tokens': 44, 'total_tokens': 338})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\n",
    "    [\n",
    "        HumanMessage(\"Hi ! I'm Akhilesh and I am a Data Scientist.\")\n",
    "       \n",
    "    ], \n",
    "    config= config\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4568cb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Akhilesh.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 351, 'total_tokens': 360, 'completion_time': 0.004084405, 'prompt_time': 0.023513823, 'queue_time': 0.019940884, 'total_time': 0.027598228}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_75db6866d3', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--29f66afc-c474-4417-b7f4-67cda25bacef-0', usage_metadata={'input_tokens': 351, 'output_tokens': 9, 'total_tokens': 360})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\n",
    "    [\n",
    "        HumanMessage(\"What is my name\")\n",
    "       \n",
    "    ], \n",
    "    config= config\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ca986f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You still haven't mentioned where you stay, Akhilesh. If you'd like to share your location, I'm happy to chat with you about it.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 373, 'total_tokens': 407, 'completion_time': 0.042783512, 'prompt_time': 0.020513154, 'queue_time': 0.05393438, 'total_time': 0.063296666}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4dea31877a', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--ad0a7d3c-e5a4-418b-af4f-caba8915e125-0', usage_metadata={'input_tokens': 373, 'output_tokens': 34, 'total_tokens': 407})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\n",
    "    [\n",
    "        HumanMessage(\"Where do I stay\")\n",
    "       \n",
    "    ], \n",
    "    config= config\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f54a08",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf2fea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate , MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a956e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "\n",
    "    (\"system\" , \"You are a helpful AI assistant. STRICTLY Gives answers to User Queries without additional content.\" ) , \n",
    "    (\"user\" , \"Translate the given sentence : {sentence} into given language : {language}\")\n",
    "\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48b46aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f019b9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Bonjour ! Je m'appelle Akhilesh.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 71, 'total_tokens': 83, 'completion_time': 0.01057041, 'prompt_time': 0.004114196, 'queue_time': 0.019972423, 'total_time': 0.014684606}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_75db6866d3', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--3008d21a-9667-4f8a-8fd0-878bbbff418f-0', usage_metadata={'input_tokens': 71, 'output_tokens': 12, 'total_tokens': 83})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke( { \"sentence\" : \"Hi! I'm Akhilesh\" , \n",
    "               \"language\" : \"French\"\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0f9231",
   "metadata": {},
   "source": [
    "### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e43ef7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "\n",
    "    (\"system\" , \"You are a helpful AI assistant. STRICTLY convert the language into given : {language} without additional content.\" ) , \n",
    "    MessagesPlaceholder(variable_name= \"query\")\n",
    "\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "639d2257",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "06a86366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='आपका नाम अक्षयेश है।', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 63, 'total_tokens': 75, 'completion_time': 0.022538991, 'prompt_time': 0.003416807, 'queue_time': 0.021227091, 'total_time': 0.025955798}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_6b5c123dd9', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--6a27f3c0-9ded-432c-90c9-eb74b488379c-0', usage_metadata={'input_tokens': 63, 'output_tokens': 12, 'total_tokens': 75})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke( { \"language\" : \"Hindi\" , \n",
    "\"query\" : [HumanMessage(\"My name is Akhilesh\")]\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e636642",
   "metadata": {},
   "source": [
    "### Memory Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4adc80d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = { \"configurable\" : {\"session_id\" : \"chat4\"} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "26e539e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = RunnableWithMessageHistory(chain, get_session_history , input_messages_key= \"query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "817926a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='مرحباً أخوكم أخلش، أَنَا بَخّاشِف بيانات.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 70, 'total_tokens': 94, 'completion_time': 0.0753885, 'prompt_time': 0.003743838, 'queue_time': 0.02070993, 'total_time': 0.079132338}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_6b5c123dd9', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--6e647b72-0bfb-4782-b869-fe1aa8b159e8-0', usage_metadata={'input_tokens': 70, 'output_tokens': 24, 'total_tokens': 94})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(  { \"query\" : [HumanMessage(\"Hi I'm Akhilesh and I'm a Data Scientist\")] , \n",
    "              \"language\" : \"Persain\"\n",
    "}, \n",
    "config = config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802a2b13",
   "metadata": {},
   "source": [
    "### Trim Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "647294b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import trim_messages\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "335dd21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "\n",
    "    (\"system\" , \"You are a helpful AI assistant.\" ) , \n",
    "    MessagesPlaceholder(variable_name= \"messages\")\n",
    "\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2ff64821",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer = trim_messages( max_tokens = 50 , \n",
    "                        strategy = \"last\" , \n",
    "                        token_counter = model , \n",
    "                        include_system=True,\n",
    "                        allow_partial=False ,                        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "43902bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are an AI assistant that answers accurately.\"),\n",
    "    \n",
    "    HumanMessage(content=\"Hi, My name is Akhilesh\"),\n",
    "    AIMessage(content=\"Hi, Nice to meet you Akhilesh.\"),\n",
    "    \n",
    "    HumanMessage(content=\"Explain LangChain in simple terms.\"),\n",
    "    AIMessage(content=\"LangChain helps connect LLMs with external tools.\"),\n",
    "    \n",
    "    HumanMessage(content=\"Give me an example of a prompt template.\"),\n",
    "    AIMessage(content=\"Here is a basic example...\"),\n",
    "    \n",
    "    HumanMessage(content=\"What is vector similarity search?\"),\n",
    "    AIMessage(content=\"It compares vector embeddings to find similar items.\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "43cf5138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are an AI assistant that answers accurately.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Here is a basic example...', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is vector similarity search?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='It compares vector embeddings to find similar items.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke( messages )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5da0766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0f8479f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnablePassthrough.assign(messages = itemgetter(\"messages\") | trimmer ) \n",
    "    | prompt\n",
    "    | model\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "93d02622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You haven't told me your name. I'm a conversational AI, and I don't have the ability to retain information about individual users. Each time you interact with me, it's a new conversation. If you'd like to share your name, I'd be happy to use it in our conversation!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 92, 'total_tokens': 155, 'completion_time': 0.066638211, 'prompt_time': 0.005018292, 'queue_time': 0.021968916, 'total_time': 0.071656503}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_6b5c123dd9', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--faec570f-47f6-4e79-b2a8-48fec8364cfc-0', usage_metadata={'input_tokens': 92, 'output_tokens': 63, 'total_tokens': 155})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({ \"messages\" : messages + [HumanMessage(\"What is my name?\")]\n",
    "              \n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf42daa",
   "metadata": {},
   "source": [
    "# Vector stores and retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ef399f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fbeaf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d3e226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdf8669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880dcea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a1e285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
